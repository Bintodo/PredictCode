{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Allow us to load `open_cp` without installing\n",
    "import sys, os.path\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with SaTScan\n",
    "\n",
    "Having discovered further trouble replicating the results of SaTScan, we introduce some more support for reading and writing SaTScan files, and test various corner cases.\n",
    "\n",
    "The class `AbstractSTScan` works with \"generic time\" (so just numbers, now interpretted as some time unit _before_ an epoch time).  This allows us to concentrate on the details.  We also introduce a more complicated rule about cases when the boundary of a disc contains more than one point (see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import open_cp.stscan, open_cp.stscan2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_random_data():\n",
    "    times = np.floor(np.random.random(size=100) * 200)\n",
    "    times.sort()\n",
    "    times = np.flipud(times)\n",
    "    coords = np.random.random(size=(2,100)) * 100\n",
    "    return coords, times\n",
    "\n",
    "def build_ab_scan(coords, times):\n",
    "    ab_scan = open_cp.stscan2.AbstractSTScan(coords, times)\n",
    "    ab_scan.geographic_radius_limit = 1000\n",
    "    ab_scan.geographic_population_limit = 0.5\n",
    "    ab_scan.time_max_interval = 200\n",
    "    ab_scan.time_population_limit = 0.5\n",
    "    return ab_scan\n",
    "\n",
    "def build_trainer(coords, times):\n",
    "    \"\"\"Convert to days before 2017-04-01 and use `STSTrainer`.\"\"\"\n",
    "    timestamps = (np.timedelta64(1,\"D\") / np.timedelta64(1,\"s\")) * times * np.timedelta64(1,\"s\")\n",
    "    timestamps = np.datetime64(\"2017-04-01T00:00\") - timestamps\n",
    "    data = open_cp.data.TimedPoints(timestamps, coords)\n",
    "\n",
    "    trainer = open_cp.stscan.STSTrainer()\n",
    "    trainer.data = data\n",
    "    trainer.time_max_interval = np.timedelta64(200,\"D\")\n",
    "    trainer.time_population_limit = 0.5\n",
    "    trainer.geographic_population_limit = 0.5\n",
    "    trainer.geographic_radius_limit = 1000\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "\n",
    "We find that _most_ of the time, we obtain the same clusters.  But sometimes we don't.  This is down to:\n",
    "\n",
    "- Non-deterministic ordering.  If we compare things in different orders, we can break ties in different ways.\n",
    "- As the discs are always centred on events, it is possible for different discs to contain the same events.  As we generate further clusters by finding the next most significant cluster which is _disjoint_ for current clusters, if we again process things in a different order, then we can obtain different disks.\n",
    "\n",
    "From this point of view, obtaining perfect agreement with SaTScan seems an almost hopeless ideal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 47.7583294   79.80132806] 21.1470597081 9.0 3.8239455272\n",
      "[ 12.96456247  32.47863865] 6.77699923599 32.0 1.89781609396\n",
      "[ 49.09593276  18.68854038] 4.65419610183 66.0 1.33652984035\n",
      "[ 93.94502034  64.27771926] 22.8324256358 15.0 1.2377140172\n",
      "[ 80.13923462  16.13742495] 10.3301961977 82.0 1.01886049118\n",
      "[ 55.9165906   40.56776161] 9.68113378677 78.0 0.877923733363\n",
      "[  2.55182235  62.80109178] 25.1985193203 85.0 0.757036668024\n",
      "[ 29.97718124   4.63486825] 10.8741986427 76.0 0.743358791298\n"
     ]
    }
   ],
   "source": [
    "coords, times = make_random_data()\n",
    "ab_scan = build_ab_scan(coords, times)\n",
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster(centre=array([ 47.7583294 ,  79.80132806]), radius=21.147271178651728) 9.0 3.8239455272\n",
      "Cluster(centre=array([ 10.32565546,  38.72074474]), radius=6.7770670059800882) 32.0 1.89781609396\n",
      "Cluster(centre=array([ 49.09593276,  18.68854038]), radius=4.6542426437907478) 66.0 1.33652984035\n",
      "Cluster(centre=array([ 93.94502034,  64.27771926]), radius=22.832653960059005) 15.0 1.2377140172\n",
      "Cluster(centre=array([ 82.69369159,   6.78297889]), radius=9.8332259659759718) 82.0 1.01886049118\n",
      "Cluster(centre=array([ 55.9165906 ,  40.56776161]), radius=9.6812305981065947) 78.0 0.877923733363\n",
      "Cluster(centre=array([ 29.97718124,   4.63486825]), radius=10.874307384696504) 76.0 0.743358791298\n",
      "Cluster(centre=array([ 12.74989957,  59.64349518]), radius=10.67583601591971) 85.0 0.124080354492\n",
      "Cluster(centre=array([  3.78541391,  92.72426815]), radius=21.246367657690392) 67.0 0.115179159952\n"
     ]
    }
   ],
   "source": [
    "trainer = build_trainer(coords, times)\n",
    "result = trainer.predict(time=np.datetime64(\"2017-04-01T00:00\"))\n",
    "for c, t, s in zip(result.clusters, result.time_ranges, result.statistics):\n",
    "    assert np.datetime64(\"2017-04-01T00:00\") == t[1]\n",
    "    t = (np.datetime64(\"2017-04-01T00:00\") - t[0]) / np.timedelta64(1,\"D\")\n",
    "    print(c, t, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Timings\n",
    "\n",
    "The newer code in `AbstractSTScan` is a bit quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.48 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit( list(ab_scan.find_all_clusters()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.5 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit( trainer.predict() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optionally save\n",
    "\n",
    "We can write the data out in SaTScan format for comparison purposes.  Be sure to adjust Advanced Analysis options in SaTScan to reflect the settings we used above (no limit of size of clusters, but a population limit of 50% for both space and time).~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ab_scan.to_satscan(\"satscan_test2\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grided data\n",
    "\n",
    "Where we have found quite different behaviour from SaTScan is in \"boundary\" behaviour.  Consider the case when a disk's boundary (it's circumference) contains more than one event.  The `STSTrainer` class always considers all events inside or on the edge of the disk.  But SaTScan will _sometimes_ consider events inside the disc, and then only _some_ of the events on the boundary.\n",
    "\n",
    "Notice in particular that we can expect this to happen a lot if the input data is on a regular grid.\n",
    "\n",
    "We try to replicate this behaviour in `AbstractSTScan` by considering all possibilities of events on the boundary being counted or not.  Unfortunately, we then seem to beat SaTScan at its own game, and consider too many subsets, resulting in finding clusters which SaTScan does not.\n",
    "\n",
    "Using the Chicago data, conformed to a grid, we found an example where SaTScan seems to perform this \"boundary behaviour\".  We have not been able to replicate it with random data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate example random data\n",
    "\n",
    "We use the grid abilities of `STSTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainer_to_data(trainer):\n",
    "    coords = trainer.data.coords\n",
    "    times = (np.datetime64(\"2017-04-01T00:00\") - trainer.data.timestamps) / np.timedelta64(1,\"s\")\n",
    "    times /= (np.timedelta64(1,\"D\") / np.timedelta64(1,\"s\"))\n",
    "    times = np.floor(times)\n",
    "    \n",
    "    return coords, times\n",
    "\n",
    "np.testing.assert_array_almost_equal(trainer_to_data(trainer)[0], coords)\n",
    "np.testing.assert_array_almost_equal(trainer_to_data(trainer)[1], times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = build_trainer(*make_random_data())\n",
    "region = open_cp.RectangularRegion(xmin=0, ymin=0, xmax=100, ymax=100)\n",
    "ab_scan = build_ab_scan( *trainer_to_data( trainer.grid_coords(region, grid_size=20) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.  30.] 20.0 7.0 3.35205338619\n",
      "[ 50.  50.] 0.0 38.0 2.71560614559\n",
      "[ 90.  70.] 0.0 29.0 1.09086496593\n",
      "[ 70.  90.] 0.0 27.0 0.639868972963\n",
      "[ 10.  90.] 0.0 60.0 0.43341798412\n",
      "[ 90.  90.] 0.0 84.0 0.367754306996\n",
      "[ 90.  10.] 0.0 42.0 0.316663808549\n",
      "[ 10.  10.] 0.0 98.0 0.221514808107\n",
      "[ 70.  10.] 0.0 93.0 0.166852706468\n",
      "[ 30.  70.] 0.0 63.0 0.133405703443\n",
      "[ 30.  90.] 0.0 97.0 0.0871975764851\n",
      "[ 10.  50.] 0.0 34.0 0.0871975764851\n",
      "[ 50.  70.] 0.0 64.0 0.0173811215268\n",
      "[ 50.  10.] 0.0 87.0 0.00689368813393\n"
     ]
    }
   ],
   "source": [
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_scan.to_satscan(\"satscan_test1\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload some data\n",
    "\n",
    "Here's one we prepared earlier.  It shows a case where our aggressive algorithm finds a cluster which SaTScan does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_satscan_ids_for_mask(in_disc, time):\n",
    "    in_disc &= ab_scan.timestamps <= time\n",
    "    in_disc = set( (x,y) for x,y in ab_scan.coords[:,in_disc].T )\n",
    "    return [i for i in satscan_data.geo if satscan_data.geo[i] in in_disc]\n",
    "\n",
    "def find_mask(centre, radius):\n",
    "    return np.sum((ab_scan.coords - np.array(centre)[:,None])**2, axis=0) <= radius**2\n",
    "\n",
    "def to_our_indexes(sat_scan_indexes):\n",
    "    out = set()\n",
    "    for i in sat_scan_indexes:\n",
    "        x, y = satscan_data.geo[i]\n",
    "        m = (ab_scan.coords[0] == x) & (ab_scan.coords[1] == y)\n",
    "        for j in np.arange(ab_scan.coords.shape[1])[m]:\n",
    "            out.add(j)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50.  30.] 20.0 45 1.78403489846\n",
      "[ 30.  70.] 20.0 13 1.2377140172\n",
      "[ 90.  70.] 0.0 20 0.719563298144\n",
      "[ 10.  30.] 0.0 70 0.532363441331\n",
      "[ 70.  10.] 0.0 55 0.253033910799\n",
      "[ 10.  90.] 0.0 42 0.124080354492\n",
      "[ 70.  70.] 0.0 97 0.0766353331714\n",
      "[ 90.  90.] 0.0 97 0.0766353331714\n",
      "[ 10.  50.] 0.0 46 0.0173811215268\n",
      "[ 90.  30.] 0.0 91 0.0109248357106\n"
     ]
    }
   ],
   "source": [
    "satscan_data = open_cp.stscan2.SaTScanData(\"satscan_test3\", 1000)\n",
    "ab_scan = build_ab_scan( *satscan_data.to_coords_time() )\n",
    "\n",
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 21, 22]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster which SaTScan finds -- In this case, seemingly SaTScan includes all events\n",
    "in_disc = find_mask([30,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 9, 11, 21]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our cluster-- all events in or on the disc\n",
    "in_disc = find_mask([50,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 9, 11, 21]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The subset of events our algorithm chooses to use\n",
    "in_disc = all_clusters[0].mask\n",
    "find_satscan_ids_for_mask(in_disc, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_time_mask(coords, time):\n",
    "    ab_scan = build_ab_scan(coords, times)\n",
    "    un_times, cutoff = ab_scan.build_times_cutoff()\n",
    "    time_mask = times[:,None] <= un_times[None,:]\n",
    "    time_counts = np.sum(time_mask, axis=0)\n",
    "    return time_mask, time_counts\n",
    "\n",
    "def clusters_around(time_mask, time_counts, centre):\n",
    "    distsq = np.sum( (coords - pt[:,None])**2, axis=0 )\n",
    "    unique_dists = np.unique(distsq)\n",
    "    mask = distsq[:,None] <= unique_dists[None,:]\n",
    "    \n",
    "    # Clamp\n",
    "    temp_counts = np.sum(mask, axis=0)\n",
    "    mask = mask[:,(temp_counts > 1) & (temp_counts <= 50)]\n",
    "    \n",
    "    space_counts = np.sum(mask, axis=0)\n",
    "    uber_mask = mask[:,:,None] & time_mask[:,None,:]\n",
    "    actual_counts = np.sum(uber_mask, axis=0)\n",
    "    expected = (space_counts[:,None] * time_counts[None,:]) / 100\n",
    "    want = (actual_counts > 1) & (actual_counts > expected)\n",
    "    \n",
    "    cluster_masks = uber_mask[:,want]\n",
    "    return cluster_masks, actual_counts[want], expected[want]\n",
    "\n",
    "def best(coords, times):\n",
    "    # Not working...\n",
    "    ab_scan = build_ab_scan(coords, times)\n",
    "    time_mask, time_counts = make_time_mask(coords, times)\n",
    "    results = []\n",
    "    for centre in coords.T:\n",
    "        cluster_masks, actual, expected = clusters_around(time_mask, time_counts, centre)\n",
    "        stats = ab_scan._statistic(actual, expected, len(times))\n",
    "        for c, s in zip(cluster_masks.T, stats):\n",
    "            results.append((c,s))\n",
    "    results.sort(key = lambda p : p[1])\n",
    "    return results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords, times = make_random_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ab_scan = build_ab_scan(coords, times)\n",
    "all_choices = list(ab_scan.score_clusters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_mask, time_counts = make_time_mask(coords, times)\n",
    "cluster_masks, actual, expected = clusters_around(time_mask, time_counts, coords[:,0])\n",
    "stats = ab_scan._statistic(actual, expected, len(times))\n",
    "\n",
    "for mask, stat in zip(cluster_masks.T, stats):\n",
    "    for c in all_choices:\n",
    "        m, s = c[0].mask, c[2]\n",
    "        if np.all(m == mask):\n",
    "            print(s, stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False,  True, False, False,  True, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False, False], dtype=bool),\n",
       " 1.2941428696750181)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best(coords, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(centre=array([ 93.47533489,  62.56407798]), radius=14.776960605640376, mask=array([False,  True,  True, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False], dtype=bool), time=8.0, statistic=4.6108152675742087)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_scan = build_ab_scan(coords, times)\n",
    "list(ab_scan.find_all_clusters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt = coords[:,0]\n",
    "distsq = np.sum( (coords - pt[:,None])**2, axis=0 )\n",
    "unique_dists = np.unique(distsq)\n",
    "mask = distsq[:,None] <= unique_dists[None,:]\n",
    "# mask[:,i] = mask for distance i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clamp to disks with <= 50% of population\n",
    "mask = mask[:,np.sum(mask, axis=0) <= 50]\n",
    "space_counts = np.sum(mask, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ab_scan = build_ab_scan(coords, times)\n",
    "un_times, cutoff = ab_scan.build_times_cutoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_mask = times[:,None] <= un_times[None,:]\n",
    "time_counts = np.sum(time_mask, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uber_mask = mask[:,:,None] & time_mask[:,None,:]\n",
    "actual_counts = np.sum(uber_mask, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected = (space_counts[:,None] * time_counts[None,:]) / 100\n",
    "want = (actual_counts > 1) & (actual_counts > expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1578)\n",
      "(1578,)\n",
      "(1578,)\n"
     ]
    }
   ],
   "source": [
    "# Masks for clusters\n",
    "print(uber_mask[:,want].shape)\n",
    "# actual counts\n",
    "print(actual_counts[want].shape)\n",
    "# expected counts\n",
    "print(expected[want].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.34589998,  1.01785138,  0.84643009, ...,  0.4233791 ,\n",
       "        0.52691134,  0.6401457 ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_scan._statistic(actual_counts[want], expected[want], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 199.,  199.,  198.,  197.,  192.,  191.,  191.,  185.,  183.,\n",
       "        181.,  179.,  173.,  171.,  170.,  168.,  167.,  166.,  166.,\n",
       "        165.,  163.,  158.,  155.,  153.,  150.,  147.,  147.,  142.,\n",
       "        142.,  139.,  139.,  137.,  132.,  128.,  126.,  123.,  122.,\n",
       "        121.,  121.,  119.,  118.,  117.,  116.,  115.,  112.,  111.,\n",
       "        109.,  107.,  106.,  104.,  102.,   99.,   97.,   95.,   93.,\n",
       "         93.,   89.,   89.,   86.,   86.,   85.,   80.,   79.,   77.,\n",
       "         68.,   65.,   60.,   60.,   60.,   59.,   56.,   56.,   53.,\n",
       "         52.,   51.,   49.,   45.,   44.,   41.,   40.,   39.,   37.,\n",
       "         35.,   33.,   32.,   32.,   23.,   23.,   23.,   22.,   16.,\n",
       "         15.,   13.,   10.,    8.,    7.,    5.,    4.,    3.,    2.,    0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
