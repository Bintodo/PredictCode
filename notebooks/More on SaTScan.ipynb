{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Allow us to load `open_cp` without installing\n",
    "import sys, os.path\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with SaTScan\n",
    "\n",
    "Having discovered further trouble replicating the results of SaTScan, we introduce some more support for reading and writing SaTScan files, and test various corner cases.\n",
    "\n",
    "The class `AbstractSTScan` works with \"generic time\" (so just numbers, now interpretted as some time unit _before_ an epoch time).  This allows us to concentrate on the details.  We also introduce a more complicated rule about cases when the boundary of a disc contains more than one point (see below).\n",
    "\n",
    "The class `STScanNumpy` takes the same data and settings as `AbstractSTScan`, but uses a parallel `numpy` programme style to improve performance.  Like the original implementation, and unlike `AbstractSTScan`, it does nothing special about events which fall on the boundary of disks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import open_cp.stscan, open_cp.stscan2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_random_data(s=100):\n",
    "    times = np.floor(np.random.random(size=s) * 200)\n",
    "    times.sort()\n",
    "    times = np.flipud(times)\n",
    "    coords = np.random.random(size=(2,s)) * 100\n",
    "    return coords, times\n",
    "\n",
    "def build_ab_scan(coords, times):\n",
    "    ab_scan = open_cp.stscan2.AbstractSTScan(coords, times)\n",
    "    ab_scan.geographic_radius_limit = 1000\n",
    "    ab_scan.geographic_population_limit = 0.5\n",
    "    ab_scan.time_max_interval = 200\n",
    "    ab_scan.time_population_limit = 0.5\n",
    "    return ab_scan\n",
    "\n",
    "def build_stscan_numpy(coords, times):\n",
    "    stsn = open_cp.stscan2.STScanNumpy(coords, times)\n",
    "    stsn.geographic_radius_limit = 1000\n",
    "    stsn.geographic_population_limit = 0.5\n",
    "    stsn.time_max_interval = 200\n",
    "    stsn.time_population_limit = 0.5\n",
    "    return stsn\n",
    "\n",
    "def build_trainer(coords, times):\n",
    "    \"\"\"Convert to days before 2017-04-01 and use `STSTrainer`.\"\"\"\n",
    "    timestamps = (np.timedelta64(1,\"D\") / np.timedelta64(1,\"s\")) * times * np.timedelta64(1,\"s\")\n",
    "    timestamps = np.datetime64(\"2017-04-01T00:00\") - timestamps\n",
    "    data = open_cp.data.TimedPoints(timestamps, coords)\n",
    "\n",
    "    trainer = open_cp.stscan.STSTrainer()\n",
    "    trainer.data = data\n",
    "    trainer.time_max_interval = np.timedelta64(200,\"D\")\n",
    "    trainer.time_population_limit = 0.5\n",
    "    trainer.geographic_population_limit = 0.5\n",
    "    trainer.geographic_radius_limit = 1000\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "\n",
    "We find that _most_ of the time, we obtain the same clusters.  But sometimes we don't.  This is down to:\n",
    "\n",
    "- Non-deterministic ordering.  If we compare things in different orders, we can break ties in different ways.\n",
    "- As the discs are always centred on events, it is possible for different discs to contain the same events.  As we generate further clusters by finding the next most significant cluster which is _disjoint_ for current clusters, if we again process things in a different order, then we can obtain different disks.\n",
    "\n",
    "From this point of view, obtaining perfect agreement with SaTScan seems an almost hopeless ideal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39.39450651  11.64804459] 7.23863176414 12.0 3.47595088648\n",
      "[ 58.98350478  55.9968803 ] 7.05372388004 14.0 3.22851754546\n",
      "[ 74.61503364  82.435939  ] 8.39513086983 40.0 2.45752362687\n",
      "[ 75.81195561   4.59675854] 24.0500060126 99.0 2.0236429117\n",
      "[  8.6832231   60.68623495] 7.53382130091 38.0 1.71470645414\n",
      "[ 41.24636169  35.36928829] 14.3200660263 67.0 1.63387376448\n",
      "[ 47.66461831  66.9936521 ] 8.44747770123 44.0 0.827100083921\n",
      "[ 67.58686735  39.86486968] 7.03861618107 92.0 0.771589596938\n",
      "[ 91.45933193  57.26196615] 19.7145143586 21.0 0.771589596938\n",
      "[ 95.26341229  95.42831613] 6.15209269847 65.0 0.624903463193\n",
      "[  6.11004592  28.1836016 ] 2.76052709341 98.0 0.610243804307\n",
      "[ 6.58072034  0.04479057] 10.336592645 111.0 0.43341798412\n",
      "[ 28.41861036  56.04295591] 9.12180322319 104.0 0.169569507969\n",
      "[ 31.11676131  91.70087877] 15.9479274003 69.0 0.0947048652956\n"
     ]
    }
   ],
   "source": [
    "coords, times = make_random_data()\n",
    "ab_scan = build_ab_scan(coords, times)\n",
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39.39450651  11.64804459] 7.23863176414 12.0 3.47595088648\n",
      "[ 58.98350478  55.9968803 ] 7.05372388004 14.0 3.22851754546\n",
      "[ 74.61503364  82.435939  ] 8.39513086983 40.0 2.45752362687\n",
      "[ 75.81195561   4.59675854] 24.0500060126 99.0 2.0236429117\n",
      "[  1.77061675  63.68195472] 7.53382130091 38.0 1.71470645414\n",
      "[ 55.56164526  34.9992244 ] 7.02349773996 67.0 1.68259534707\n",
      "[ 39.63769216  45.33736925] 9.20489730295 42.0 1.48054158004\n",
      "[ 47.66461831  66.9936521 ] 8.44747770123 44.0 0.827100083921\n",
      "[ 91.45933193  57.26196615] 19.7145143586 21.0 0.771589596938\n",
      "[ 95.26341229  95.42831613] 6.15209269847 65.0 0.624903463193\n",
      "[  6.11004592  28.1836016 ] 2.76052709341 98.0 0.610243804307\n",
      "[ 6.58072034  0.04479057] 10.336592645 111.0 0.43341798412\n",
      "[ 31.11676131  91.70087877] 15.9479274003 69.0 0.0947048652956\n"
     ]
    }
   ],
   "source": [
    "stsn = build_stscan_numpy(coords, times)\n",
    "all_clusters = list(stsn.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster(centre=array([ 39.39450651,  11.64804459]), radius=7.238704150455912) 12.0 3.47595088648\n",
      "Cluster(centre=array([ 58.98350478,  55.9968803 ]), radius=7.0537944172824991) 14.0 3.22851754546\n",
      "Cluster(centre=array([ 74.61503364,  82.435939  ]), radius=8.3952148211387918) 40.0 2.45752362687\n",
      "Cluster(centre=array([ 75.81195561,   4.59675854]), radius=24.050246512630547) 99.0 2.0236429117\n",
      "Cluster(centre=array([  1.77061675,  63.68195472]), radius=7.533896639125981) 38.0 1.71470645414\n",
      "Cluster(centre=array([ 55.56164526,  34.9992244 ]), radius=7.0235679749363724) 67.0 1.68259534707\n",
      "Cluster(centre=array([ 39.63769216,  45.33736925]), radius=9.2049893519203039) 42.0 1.48054158004\n",
      "Cluster(centre=array([ 47.66461831,  66.9936521 ]), radius=8.4475621760102939) 44.0 0.827100083921\n",
      "Cluster(centre=array([ 91.45933193,  57.26196615]), radius=19.714711503762064) 21.0 0.771589596938\n",
      "Cluster(centre=array([ 95.26341229,  95.42831613]), radius=6.1521542194007752) 65.0 0.624903463193\n",
      "Cluster(centre=array([  6.11004592,  28.1836016 ]), radius=2.7605546986823231) 98.0 0.610243804307\n",
      "Cluster(centre=array([ 6.58072034,  0.04479057]), radius=10.336696010974521) 111.0 0.43341798412\n",
      "Cluster(centre=array([ 31.11676131,  91.70087877]), radius=15.948086879585571) 69.0 0.0947048652956\n"
     ]
    }
   ],
   "source": [
    "trainer = build_trainer(coords, times)\n",
    "result = trainer.predict(time=np.datetime64(\"2017-04-01T00:00\"))\n",
    "for c, t, s in zip(result.clusters, result.time_ranges, result.statistics):\n",
    "    assert np.datetime64(\"2017-04-01T00:00\") == t[1]\n",
    "    t = (np.datetime64(\"2017-04-01T00:00\") - t[0]) / np.timedelta64(1,\"D\")\n",
    "    print(c, t, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Timings\n",
    "\n",
    "The newer code in `AbstractSTScan` is a bit quicker.  The Numpy code is somewhat quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 5.83 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit( list(ab_scan.find_all_clusters()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 560 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit( list(stsn.find_all_clusters()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 4.82 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit( trainer.predict() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optionally save\n",
    "\n",
    "We can write the data out in SaTScan format for comparison purposes.  Be sure to adjust Advanced Analysis options in SaTScan to reflect the settings we used above (no limit of size of clusters, but a population limit of 50% for both space and time).~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ab_scan.to_satscan(\"satscan_test2\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grided data\n",
    "\n",
    "Where we have found quite different behaviour from SaTScan is in \"boundary\" behaviour.  Consider the case when a disk's boundary (it's circumference) contains more than one event.  The `STSTrainer` class always considers all events inside or on the edge of the disk.  But SaTScan will _sometimes_ consider events inside the disc, and then only _some_ of the events on the boundary.\n",
    "\n",
    "Notice in particular that we can expect this to happen a lot if the input data is on a regular grid.\n",
    "\n",
    "We try to replicate this behaviour in `AbstractSTScan` by considering all possibilities of events on the boundary being counted or not.  Unfortunately, we then seem to beat SaTScan at its own game, and consider too many subsets, resulting in finding clusters which SaTScan does not.\n",
    "\n",
    "The first example below shows where `AbstractSTScan` is more aggresive than SaTScan.  The 2nd example shows where SaTScan does indeed fail to consider all events in a disc, and gets the same result as `AbstractSTScan`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate example random data\n",
    "\n",
    "We use the grid abilities of `STSTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainer_to_data(trainer):\n",
    "    coords = trainer.data.coords\n",
    "    times = (np.datetime64(\"2017-04-01T00:00\") - trainer.data.timestamps) / np.timedelta64(1,\"s\")\n",
    "    times /= (np.timedelta64(1,\"D\") / np.timedelta64(1,\"s\"))\n",
    "    times = np.floor(times)\n",
    "    \n",
    "    return coords, times\n",
    "\n",
    "np.testing.assert_array_almost_equal(trainer_to_data(trainer)[0], coords)\n",
    "np.testing.assert_array_almost_equal(trainer_to_data(trainer)[1], times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = build_trainer(*make_random_data())\n",
    "region = open_cp.RectangularRegion(xmin=0, ymin=0, xmax=100, ymax=100)\n",
    "ab_scan = build_ab_scan( *trainer_to_data( trainer.grid_coords(region, grid_size=20) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50.  30.] 20.0 4.0 3.7646267329\n",
      "[ 90.  10.] 0.0 42.0 2.44443465205\n",
      "[ 30.  90.] 0.0 28.0 2.26620053632\n",
      "[ 10.  10.] 20.0 9.0 0.949852980188\n",
      "[ 10.  70.] 20.0 73.0 0.903595490836\n",
      "[ 30.  50.] 0.0 71.0 0.813748656351\n",
      "[ 70.  10.] 0.0 97.0 0.288438169449\n",
      "[ 70.  70.] 20.0 64.0 0.174174441607\n"
     ]
    }
   ],
   "source": [
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ab_scan.to_satscan(\"satscan_test1\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload some data\n",
    "\n",
    "Here's one we prepared earlier.  It shows a case where our aggressive algorithm finds a cluster which SaTScan does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_satscan_ids_for_mask(in_disc, time):\n",
    "    in_disc &= ab_scan.timestamps <= time\n",
    "    in_disc = set( (x,y) for x,y in ab_scan.coords[:,in_disc].T )\n",
    "    return [i for i in satscan_data.geo if satscan_data.geo[i] in in_disc]\n",
    "\n",
    "def find_mask(centre, radius):\n",
    "    return np.sum((ab_scan.coords - np.array(centre)[:,None])**2, axis=0) <= radius**2\n",
    "\n",
    "def to_our_indexes(sat_scan_indexes):\n",
    "    out = set()\n",
    "    for i in sat_scan_indexes:\n",
    "        x, y = satscan_data.geo[i]\n",
    "        m = (ab_scan.coords[0] == x) & (ab_scan.coords[1] == y)\n",
    "        for j in np.arange(ab_scan.coords.shape[1])[m]:\n",
    "            out.add(j)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50.  30.] 20.0 45 1.78403489846\n",
      "[ 30.  70.] 20.0 13 1.2377140172\n",
      "[ 90.  70.] 0.0 20 0.719563298144\n",
      "[ 10.  30.] 0.0 70 0.532363441331\n",
      "[ 70.  10.] 0.0 55 0.253033910799\n",
      "[ 10.  90.] 0.0 42 0.124080354492\n",
      "[ 70.  70.] 0.0 97 0.0766353331714\n",
      "[ 90.  90.] 0.0 97 0.0766353331714\n",
      "[ 10.  50.] 0.0 46 0.0173811215268\n",
      "[ 90.  30.] 0.0 91 0.0109248357106\n"
     ]
    }
   ],
   "source": [
    "satscan_data = open_cp.stscan2.SaTScanData(\"satscan_test3\", 1000)\n",
    "ab_scan = build_ab_scan( *satscan_data.to_coords_time() )\n",
    "\n",
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 21, 22]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster which SaTScan finds -- In this case, seemingly SaTScan includes all events\n",
    "in_disc = find_mask([30,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 9, 11, 21]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our cluster-- all events in or on the disc\n",
    "in_disc = find_mask([50,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 9, 11, 21]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The subset of events our algorithm chooses to use\n",
    "in_disc = all_clusters[0].mask\n",
    "find_satscan_ids_for_mask(in_disc, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.  30.] 20.0 70 1.62216107924\n",
      "[ 30.  70.] 0.0 13 0.928218893946\n",
      "[ 90.  70.] 0.0 20 0.719563298144\n",
      "[ 90.  10.] 40.0 1 0.670748515888\n",
      "[ 50.  50.] 0.0 92 0.528417664973\n",
      "[ 10.  70.] 0.0 33 0.444466091444\n",
      "[ 10.  90.] 0.0 42 0.124080354492\n",
      "[ 90.  90.] 0.0 97 0.0766353331714\n",
      "[ 70.  70.] 0.0 97 0.0766353331714\n",
      "[ 50.  70.] 0.0 68 0.0700453772522\n",
      "[ 10.  50.] 0.0 46 0.0173811215268\n"
     ]
    }
   ],
   "source": [
    "# The numpy code should, mostly, replicate what SaTScan does\n",
    "stsn = build_stscan_numpy( *satscan_data.to_coords_time() )\n",
    "\n",
    "all_clusters = list(stsn.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Example\n",
    "\n",
    "This example actually seems to show SaTScan not including all points in a disc.  SaTScan reports:\n",
    "\n",
    "    1.Location IDs included.: 23, 6, 16\n",
    "      Coordinates / radius..: (30,30) / 20.00\n",
    "      Time frame............: 993 to 1000\n",
    "      Number of cases.......: 3\n",
    "      Expected cases........: 0.42\n",
    "      Observed / expected...: 7.14\n",
    "      Test statistic........: 3.352053\n",
    "      P-value...............: 0.202\n",
    "      Recurrence interval...: 5.0 units\n",
    "\n",
    "Now, we note that:\n",
    "- Event 23 occurs at times 967 and 924, which are both _outside_ the time window.\n",
    "- The disc centred at (30,30) of radius 20 contains events 6, 11, 16, 23 and 24.\n",
    "- If we manually compute the statistic for this disk and time, we get the same value as SaTScan (to be precise, if we change the space window to only include events 6, 16 and 23, we obtain the sample \"expected\" count).\n",
    "- The Numpy accelerated code fails to find this cluster, as it includes all events in the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.  30.] 20.0 7 3.35205338619\n",
      "[ 50.  50.] 0.0 38 2.71560614559\n",
      "[ 90.  70.] 0.0 29 1.09086496593\n",
      "[ 70.  90.] 0.0 27 0.639868972963\n",
      "[ 10.  90.] 0.0 60 0.43341798412\n",
      "[ 90.  90.] 0.0 84 0.367754306996\n",
      "[ 90.  10.] 0.0 42 0.316663808549\n",
      "[ 10.  10.] 0.0 98 0.221514808107\n",
      "[ 70.  10.] 0.0 93 0.166852706468\n",
      "[ 30.  70.] 0.0 63 0.133405703443\n",
      "[ 30.  90.] 0.0 97 0.0871975764851\n",
      "[ 10.  50.] 0.0 34 0.0871975764851\n",
      "[ 50.  70.] 0.0 64 0.0173811215268\n",
      "[ 50.  10.] 0.0 87 0.00689368813393\n"
     ]
    }
   ],
   "source": [
    "satscan_data = open_cp.stscan2.SaTScanData(\"satscan_test1\", 1000)\n",
    "coords, times = satscan_data.to_coords_time()\n",
    "ab_scan = build_ab_scan(coords, times)\n",
    "\n",
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 16]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_disc = find_mask([30,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 16, 23, 24]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_disc = find_mask([30,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10.0, 30.0), (30.0, 10.0), (50.0, 30.0), (30.0, 30.0), (30.0, 50.0))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satscan_data.geo[6], satscan_data.geo[16], satscan_data.geo[11], satscan_data.geo[23], satscan_data.geo[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.56999999999999995, 2.5821322730708438)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_mask = times <= 7\n",
    "space_mask = np.sum( (coords - np.array([30,30])[:,None])**2, axis=0) <= 20**2\n",
    "\n",
    "expected = np.sum(space_mask) * np.sum(time_mask) / 100\n",
    "actual = np.sum(space_mask & time_mask)\n",
    "actual, expected, ab_scan._statistic(actual, expected, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41999999999999998"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above Statistic is smaller than the one SaTScan finds, because the expected count is too large\n",
    "# But if we limit the spacial region to the ids SaTScan claims, we obtain a perfect match\n",
    "expected = len(to_our_indexes([23, 6, 16])) * np.sum(time_mask) / 100\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.  10.] 20.0 7 3.00992229396\n",
      "[ 50.  50.] 0.0 38 2.71560614559\n",
      "[ 90.  70.] 0.0 29 1.09086496593\n",
      "[ 50.  30.] 0.0 52 0.96536944933\n",
      "[ 70.  90.] 0.0 27 0.639868972963\n",
      "[ 30.  30.] 0.0 76 0.581812742761\n",
      "[ 10.  90.] 0.0 60 0.43341798412\n",
      "[ 90.  90.] 0.0 84 0.367754306996\n",
      "[ 90.  10.] 0.0 42 0.316663808549\n",
      "[ 70.  10.] 0.0 93 0.166852706468\n",
      "[ 30.  70.] 0.0 63 0.133405703443\n",
      "[ 10.  50.] 0.0 34 0.0871975764851\n",
      "[ 30.  90.] 0.0 97 0.0871975764851\n",
      "[ 50.  70.] 0.0 64 0.0173811215268\n",
      "[ 50.  10.] 0.0 87 0.00689368813393\n"
     ]
    }
   ],
   "source": [
    "# The numpy accelerated code doesn't find the same clusters\n",
    "stsn = build_stscan_numpy(coords, times)\n",
    "\n",
    "all_clusters = list(stsn.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
