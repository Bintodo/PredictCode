{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Allow us to load `open_cp` without installing\n",
    "import sys, os.path\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with SaTScan\n",
    "\n",
    "Having discovered further trouble replicating the results of SaTScan, we introduce some more support for reading and writing SaTScan files, and test various corner cases.\n",
    "\n",
    "The class `AbstractSTScan` works with \"generic time\" (so just numbers, now interpretted as some time unit _before_ an epoch time).  This allows us to concentrate on the details.  We also introduce a more complicated rule about cases when the boundary of a disc contains more than one point (see below).\n",
    "\n",
    "The class `STScanNumpy` takes the same data and settings as `AbstractSTScan`, but uses a parallel `numpy` programme style to improve performance.  Like the original implementation, and unlike `AbstractSTScan`, it does nothing special about events which fall on the boundary of disks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import open_cp.stscan, open_cp.stscan2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_random_data(s=100):\n",
    "    times = np.floor(np.random.random(size=s) * 200)\n",
    "    times.sort()\n",
    "    times = np.flipud(times)\n",
    "    coords = np.random.random(size=(2,s)) * 100\n",
    "    return coords, times\n",
    "\n",
    "def build_ab_scan(coords, times):\n",
    "    ab_scan = open_cp.stscan2.AbstractSTScan(coords, times)\n",
    "    ab_scan.geographic_radius_limit = 1000\n",
    "    ab_scan.geographic_population_limit = 0.5\n",
    "    ab_scan.time_max_interval = 200\n",
    "    ab_scan.time_population_limit = 0.5\n",
    "    return ab_scan\n",
    "\n",
    "def build_stscan_numpy(coords, times):\n",
    "    stsn = open_cp.stscan2.STScanNumpy(coords, times)\n",
    "    stsn.geographic_radius_limit = 1000\n",
    "    stsn.geographic_population_limit = 0.5\n",
    "    stsn.time_max_interval = 200\n",
    "    stsn.time_population_limit = 0.5\n",
    "    return stsn\n",
    "\n",
    "def build_trainer(coords, times):\n",
    "    \"\"\"Convert to days before 2017-04-01 and use `STSTrainer`.\"\"\"\n",
    "    timestamps = (np.timedelta64(1,\"D\") / np.timedelta64(1,\"s\")) * times * np.timedelta64(1,\"s\")\n",
    "    timestamps = np.datetime64(\"2017-04-01T00:00\") - timestamps\n",
    "    data = open_cp.data.TimedPoints(timestamps, coords)\n",
    "\n",
    "    trainer = open_cp.stscan.STSTrainer()\n",
    "    trainer.data = data\n",
    "    trainer.time_max_interval = np.timedelta64(200,\"D\")\n",
    "    trainer.time_population_limit = 0.5\n",
    "    trainer.geographic_population_limit = 0.5\n",
    "    trainer.geographic_radius_limit = 1000\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "\n",
    "We find that _most_ of the time, we obtain the same clusters.  But sometimes we don't.  This is down to:\n",
    "\n",
    "- Non-deterministic ordering.  If we compare things in different orders, we can break ties in different ways.\n",
    "- As the discs are always centred on events, it is possible for different discs to contain the same events.  As we generate further clusters by finding the next most significant cluster which is _disjoint_ for current clusters, if we again process things in a different order, then we can obtain different disks.\n",
    "\n",
    "From this point of view, obtaining perfect agreement with SaTScan seems an almost hopeless ideal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 76.0463809   38.61841571] 14.1534518545 21.0 3.41378564102\n",
      "[ 13.01162761  89.05301077] 18.6403373171 26.0 2.88110784848\n",
      "[ 86.01394732  94.41319336] 8.27550358952 34.0 2.16013404119\n",
      "[ 13.7945664    6.98487992] 8.89644785039 56.0 1.76235620726\n",
      "[ 62.3673206    3.26749832] 23.3302178051 79.0 1.48088533461\n",
      "[  5.45719605  56.74473893] 3.5629950544 44.0 1.48054158004\n",
      "[ 40.25486272  23.13949266] 3.84153639057 93.0 0.759399454025\n",
      "[ 21.86287589  33.84865106] 8.00744343921 82.0 0.702947397527\n",
      "[ 87.19875038  69.27759605] 13.116481675 31.0 0.503143051229\n",
      "[ 88.19261399   9.66260152] 3.03013803093 99.0 0.391361957646\n",
      "[ 50.52672761  39.18449215] 9.08707140353 80.0 0.316663808549\n",
      "[ 96.13177892   0.6935934 ] 5.76013004166 84.0 0.224898891373\n",
      "[ 48.15182531  69.70763238] 15.9227963138 62.0 0.115179159952\n",
      "[ 73.94959126  86.6563954 ] 5.87065987385 99.0 0.0766353331714\n",
      "[ 96.48532599  22.14550346] 11.5244935416 83.0 0.0579075270733\n",
      "[ 17.38307738  57.18791863] 8.33136283308 96.0 0.00689368813393\n"
     ]
    }
   ],
   "source": [
    "coords, times = make_random_data()\n",
    "ab_scan = build_ab_scan(coords, times)\n",
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 76.0463809   38.61841571] 14.1534518545 21.0 3.41378564102\n",
      "[ 14.42015592  84.40662327] 16.798875793 26.0 2.88110784848\n",
      "[ 86.01394732  94.41319336] 8.27550358952 34.0 2.16013404119\n",
      "[ 13.7945664    6.98487992] 8.89644785039 56.0 1.76235620726\n",
      "[ 62.3673206    3.26749832] 23.3302178051 79.0 1.48088533461\n",
      "[  2.21702089  55.2627812 ] 3.5629950544 44.0 1.48054158004\n",
      "[ 43.08195511  22.42432636] 3.42952690739 93.0 0.759399454025\n",
      "[ 21.86287589  33.84865106] 8.00744343921 82.0 0.702947397527\n",
      "[ 87.19875038  69.27759605] 13.116481675 31.0 0.503143051229\n",
      "[ 88.19261399   9.66260152] 3.03013803093 99.0 0.391361957646\n",
      "[ 46.9820603   36.21899903] 9.6425324934 80.0 0.316663808549\n",
      "[ 96.13177892   0.6935934 ] 5.76013004166 84.0 0.224898891373\n",
      "[ 48.15182531  69.70763238] 15.9227963138 62.0 0.115179159952\n",
      "[ 73.94959126  86.6563954 ] 5.87065987385 99.0 0.0766353331714\n",
      "[ 96.04782923  25.75960967] 8.00638076767 83.0 0.0579075270733\n",
      "[ 17.38307738  57.18791863] 8.33136283308 96.0 0.00689368813393\n"
     ]
    }
   ],
   "source": [
    "stsn = build_stscan_numpy(coords, times)\n",
    "all_clusters = list(stsn.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster(centre=array([ 76.0463809 ,  38.61841571]), radius=14.153593389044634) 21.0 3.41378564102\n",
      "Cluster(centre=array([ 14.43004833,  88.75829439]), radius=17.191943343752239) 26.0 2.88110784848\n",
      "Cluster(centre=array([ 86.01394732,  94.41319336]), radius=8.2755863445558813) 34.0 2.16013404119\n",
      "Cluster(centre=array([ 13.7945664 ,   6.98487992]), radius=8.8965368148683357) 56.0 1.76235620726\n",
      "Cluster(centre=array([ 62.3673206 ,   3.26749832]), radius=23.330451107299439) 79.0 1.48088533461\n",
      "Cluster(centre=array([  5.45719605,  56.74473893]), radius=3.5630306843498913) 44.0 1.48054158004\n",
      "Cluster(centre=array([ 40.25486272,  23.13949266]), radius=3.8415748059332011) 93.0 0.759399454025\n",
      "Cluster(centre=array([ 29.53079367,  36.15563771]), radius=8.0075235136452232) 82.0 0.702947397527\n",
      "Cluster(centre=array([ 87.19875038,  69.27759605]), radius=13.116612839783979) 31.0 0.503143051229\n",
      "Cluster(centre=array([ 88.19261399,   9.66260152]), radius=3.0301683323122002) 99.0 0.391361957646\n",
      "Cluster(centre=array([ 50.52672761,  39.18449215]), radius=9.0871622742447258) 80.0 0.316663808549\n",
      "Cluster(centre=array([ 48.15182531,  69.70763238]), radius=15.922955541747209) 62.0 0.115179159952\n",
      "Cluster(centre=array([ 73.94959126,  86.6563954 ]), radius=5.8707185804502293) 99.0 0.0766353331714\n",
      "Cluster(centre=array([ 96.48532599,  22.14550346]), radius=11.524608786548308) 83.0 0.0579075270733\n",
      "Cluster(centre=array([ 17.38307738,  57.18791863]), radius=8.3314461467088226) 96.0 0.00689368813393\n"
     ]
    }
   ],
   "source": [
    "trainer = build_trainer(coords, times)\n",
    "result = trainer.predict(time=np.datetime64(\"2017-04-01T00:00\"))\n",
    "for c, t, s in zip(result.clusters, result.time_ranges, result.statistics):\n",
    "    assert np.datetime64(\"2017-04-01T00:00\") == t[1]\n",
    "    t = (np.datetime64(\"2017-04-01T00:00\") - t[0]) / np.timedelta64(1,\"D\")\n",
    "    print(c, t, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Timings\n",
    "\n",
    "The newer code in `AbstractSTScan` is a bit quicker.  The Numpy code is somewhat quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 4.29 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit( list(ab_scan.find_all_clusters()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit( list(stsn.find_all_clusters()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3.63 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit( trainer.predict() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optionally save\n",
    "\n",
    "We can write the data out in SaTScan format for comparison purposes.  Be sure to adjust Advanced Analysis options in SaTScan to reflect the settings we used above (no limit of size of clusters, but a population limit of 50% for both space and time).~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ab_scan.to_satscan(\"satscan_test2\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grided data\n",
    "\n",
    "Where we have found quite different behaviour from SaTScan is in \"boundary\" behaviour.  Consider the case when a disk's boundary (it's circumference) contains more than one event.  The `STSTrainer` class always considers all events inside or on the edge of the disk.  But SaTScan will _sometimes_ consider events inside the disc, and then only _some_ of the events on the boundary.\n",
    "\n",
    "Notice in particular that we can expect this to happen a lot if the input data is on a regular grid.\n",
    "\n",
    "We try to replicate this behaviour in `AbstractSTScan` by considering all possibilities of events on the boundary being counted or not.  Unfortunately, we then seem to beat SaTScan at its own game, and consider too many subsets, resulting in finding clusters which SaTScan does not.\n",
    "\n",
    "The first example below shows where `AbstractSTScan` is more aggresive than SaTScan.  The 2nd example shows where SaTScan does indeed fail to consider all events in a disc, and gets the same result as `AbstractSTScan`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate example random data\n",
    "\n",
    "We use the grid abilities of `STSTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainer_to_data(trainer):\n",
    "    coords = trainer.data.coords\n",
    "    times = (np.datetime64(\"2017-04-01T00:00\") - trainer.data.timestamps) / np.timedelta64(1,\"s\")\n",
    "    times /= (np.timedelta64(1,\"D\") / np.timedelta64(1,\"s\"))\n",
    "    times = np.floor(times)\n",
    "    \n",
    "    return coords, times\n",
    "\n",
    "np.testing.assert_array_almost_equal(trainer_to_data(trainer)[0], coords)\n",
    "np.testing.assert_array_almost_equal(trainer_to_data(trainer)[1], times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = build_trainer(*make_random_data())\n",
    "region = open_cp.RectangularRegion(xmin=0, ymin=0, xmax=100, ymax=100)\n",
    "ab_scan = build_ab_scan( *trainer_to_data( trainer.grid_coords(region, grid_size=20) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ab_scan.to_satscan(\"satscan_test1\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload some data\n",
    "\n",
    "Here's one we prepared earlier.  It shows a case where our aggressive algorithm finds a cluster which SaTScan does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_satscan_ids_for_mask(in_disc, time):\n",
    "    in_disc &= ab_scan.timestamps <= time\n",
    "    in_disc = set( (x,y) for x,y in ab_scan.coords[:,in_disc].T )\n",
    "    return [i for i in satscan_data.geo if satscan_data.geo[i] in in_disc]\n",
    "\n",
    "def find_mask(centre, radius):\n",
    "    return np.sum((ab_scan.coords - np.array(centre)[:,None])**2, axis=0) <= radius**2\n",
    "\n",
    "def to_our_indexes(sat_scan_indexes):\n",
    "    out = set()\n",
    "    for i in sat_scan_indexes:\n",
    "        x, y = satscan_data.geo[i]\n",
    "        m = (ab_scan.coords[0] == x) & (ab_scan.coords[1] == y)\n",
    "        for j in np.arange(ab_scan.coords.shape[1])[m]:\n",
    "            out.add(j)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50.  30.] 20.0 45 1.78403489846\n",
      "[ 30.  70.] 20.0 13 1.2377140172\n",
      "[ 90.  70.] 0.0 20 0.719563298144\n",
      "[ 10.  30.] 0.0 70 0.532363441331\n",
      "[ 70.  10.] 0.0 55 0.253033910799\n",
      "[ 10.  90.] 0.0 42 0.124080354492\n",
      "[ 70.  70.] 0.0 97 0.0766353331714\n",
      "[ 90.  90.] 0.0 97 0.0766353331714\n",
      "[ 10.  50.] 0.0 46 0.0173811215268\n",
      "[ 90.  30.] 0.0 91 0.0109248357106\n"
     ]
    }
   ],
   "source": [
    "satscan_data = open_cp.stscan2.SaTScanData(\"satscan_test3\", 1000)\n",
    "ab_scan = build_ab_scan( *satscan_data.to_coords_time() )\n",
    "\n",
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 21, 22]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster which SaTScan finds -- In this case, seemingly SaTScan includes all events\n",
    "in_disc = find_mask([30,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 9, 11, 21]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our cluster-- all events in or on the disc\n",
    "in_disc = find_mask([50,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 9, 11, 21]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The subset of events our algorithm chooses to use\n",
    "in_disc = all_clusters[0].mask\n",
    "find_satscan_ids_for_mask(in_disc, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.  30.] 20.0 70 1.62216107924\n",
      "[ 30.  70.] 0.0 13 0.928218893946\n",
      "[ 90.  70.] 0.0 20 0.719563298144\n",
      "[ 90.  10.] 40.0 1 0.670748515888\n",
      "[ 50.  50.] 0.0 92 0.528417664973\n",
      "[ 10.  70.] 0.0 33 0.444466091444\n",
      "[ 10.  90.] 0.0 42 0.124080354492\n",
      "[ 70.  70.] 0.0 97 0.0766353331714\n",
      "[ 90.  90.] 0.0 97 0.0766353331714\n",
      "[ 50.  70.] 0.0 68 0.0700453772522\n",
      "[ 10.  50.] 0.0 46 0.0173811215268\n"
     ]
    }
   ],
   "source": [
    "# The numpy code should, mostly, replicate what SaTScan does\n",
    "stsn = build_stscan_numpy( *satscan_data.to_coords_time() )\n",
    "\n",
    "all_clusters = list(stsn.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Example\n",
    "\n",
    "This example actually seems to show SaTScan not including all points in a disc.  SaTScan reports:\n",
    "\n",
    "    1.Location IDs included.: 23, 6, 16\n",
    "      Coordinates / radius..: (30,30) / 20.00\n",
    "      Time frame............: 993 to 1000\n",
    "      Number of cases.......: 3\n",
    "      Expected cases........: 0.42\n",
    "      Observed / expected...: 7.14\n",
    "      Test statistic........: 3.352053\n",
    "      P-value...............: 0.202\n",
    "      Recurrence interval...: 5.0 units\n",
    "\n",
    "Now, we note that:\n",
    "- Event 23 occurs at times 967 and 924, which are both _outside_ the time window.\n",
    "- The disc centred at (30,30) of radius 20 contains events 6, 11, 16, 23 and 24.\n",
    "- If we manually compute the statistic for this disk and time, we get the same value as SaTScan (to be precise, if we change the space window to only include events 6, 16 and 23, we obtain the sample \"expected\" count).\n",
    "- The Numpy accelerated code fails to find this cluster, as it includes all events in the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.  30.] 20.0 7 3.35205338619\n",
      "[ 50.  50.] 0.0 38 2.71560614559\n",
      "[ 90.  70.] 0.0 29 1.09086496593\n",
      "[ 70.  90.] 0.0 27 0.639868972963\n",
      "[ 10.  90.] 0.0 60 0.43341798412\n",
      "[ 90.  90.] 0.0 84 0.367754306996\n",
      "[ 90.  10.] 0.0 42 0.316663808549\n",
      "[ 10.  10.] 0.0 98 0.221514808107\n",
      "[ 70.  10.] 0.0 93 0.166852706468\n",
      "[ 30.  70.] 0.0 63 0.133405703443\n",
      "[ 30.  90.] 0.0 97 0.0871975764851\n",
      "[ 10.  50.] 0.0 34 0.0871975764851\n",
      "[ 50.  70.] 0.0 64 0.0173811215268\n",
      "[ 50.  10.] 0.0 87 0.00689368813393\n"
     ]
    }
   ],
   "source": [
    "satscan_data = open_cp.stscan2.SaTScanData(\"satscan_test1\", 1000)\n",
    "coords, times = satscan_data.to_coords_time()\n",
    "ab_scan = build_ab_scan(coords, times)\n",
    "\n",
    "all_clusters = list(ab_scan.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 16]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_disc = find_mask([30,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 16, 23, 24]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_disc = find_mask([30,30], 20)\n",
    "find_satscan_ids_for_mask(in_disc,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10.0, 30.0), (30.0, 10.0), (50.0, 30.0), (30.0, 30.0), (30.0, 50.0))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satscan_data.geo[6], satscan_data.geo[16], satscan_data.geo[11], satscan_data.geo[23], satscan_data.geo[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.56999999999999995, 2.5821322730708438)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_mask = times <= 7\n",
    "space_mask = np.sum( (coords - np.array([30,30])[:,None])**2, axis=0) <= 20**2\n",
    "\n",
    "expected = np.sum(space_mask) * np.sum(time_mask) / 100\n",
    "actual = np.sum(space_mask & time_mask)\n",
    "actual, expected, ab_scan._statistic(actual, expected, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41999999999999998"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above Statistic is smaller than the one SaTScan finds, because the expected count is too large\n",
    "# But if we limit the spacial region to the ids SaTScan claims, we obtain a perfect match\n",
    "expected = len(to_our_indexes([23, 6, 16])) * np.sum(time_mask) / 100\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.  10.] 20.0 7 3.00992229396\n",
      "[ 50.  50.] 0.0 38 2.71560614559\n",
      "[ 90.  70.] 0.0 29 1.09086496593\n",
      "[ 50.  30.] 0.0 52 0.96536944933\n",
      "[ 70.  90.] 0.0 27 0.639868972963\n",
      "[ 30.  30.] 0.0 76 0.581812742761\n",
      "[ 10.  90.] 0.0 60 0.43341798412\n",
      "[ 90.  90.] 0.0 84 0.367754306996\n",
      "[ 90.  10.] 0.0 42 0.316663808549\n",
      "[ 70.  10.] 0.0 93 0.166852706468\n",
      "[ 30.  70.] 0.0 63 0.133405703443\n",
      "[ 30.  90.] 0.0 97 0.0871975764851\n",
      "[ 10.  50.] 0.0 34 0.0871975764851\n",
      "[ 50.  70.] 0.0 64 0.0173811215268\n",
      "[ 50.  10.] 0.0 87 0.00689368813393\n"
     ]
    }
   ],
   "source": [
    "# The numpy accelerated code doesn't find the same clusters\n",
    "stsn = build_stscan_numpy(coords, times)\n",
    "\n",
    "all_clusters = list(stsn.find_all_clusters())\n",
    "for c in all_clusters:\n",
    "    print(c.centre, c.radius, c.time, c.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
